# üìä POC ‚Äì Gestion de tickets clients avec Redpanda et PySpark

## Contexte

Dans le cadre de l‚Äôexercice 2, InduTech souhaite r√©aliser un **POC (Proof Of Concept)** afin de d√©montrer la mise en place d‚Äôun pipeline de donn√©es temps r√©el pour la gestion de tickets clients.

Les tickets sont g√©n√©r√©s en continu et ing√©r√©s via **Redpanda (Kafka-compatible)**, puis trait√©s et analys√©s en **temps r√©el avec PySpark**.

Ce projet simule une architecture moderne orient√©e streaming, telle qu‚Äôelle pourrait √™tre d√©ploy√©e dans un environnement cloud (AWS).

---

## Objectifs du projet

- Configurer un cluster **Redpanda** pour l‚Äôingestion de donn√©es temps r√©el
- Produire des tickets clients al√©atoires via un **script Python**
- Consommer et transformer ces donn√©es avec **PySpark Structured Streaming**
- G√©n√©rer des **insights temps r√©el**
- Orchestrer l‚Äôensemble avec **Docker Compose**

---

## Donn√©es manipul√©es

Chaque ticket client contient les champs suivants :

- `ticket_id` : identifiant unique du ticket
- `client_id` : identifiant du client
- `created_at` : date et heure de cr√©ation
- `request` : description de la demande
- `type` : type de demande (`incident`, `demande`, `question`)
- `priority` : priorit√© (`low`, `medium`, `high`)

---

## Architecture du pipeline

<p align="center">
  <img src="media/Diagrammeexercice2.drawio.png" alt="Diagramme du pipeline ETL" width="900"/>
</p>

flowchart LR
    Producer[Python Producer] -->|Kafka| Redpanda[(Redpanda)]
    Redpanda --> SparkConsumer[PySpark Streaming]
    Redpanda --> SparkAgg[PySpark Aggregations]
    SparkConsumer --> ConsoleLogs[Affichage temps r√©el]
    SparkAgg --> ConsoleAgg[Agr√©gations temps r√©el]

## Description des composants

### üîπ Redpanda
- Broker Kafka-compatible
- R√©ception des tickets en temps r√©el
- Expos√© sur le port **9092**

### üîπ Producer (Python)
- G√©n√®re des tickets clients al√©atoires en continu
- Envoie les messages dans le topic **`client_tickets`**
- Impl√©ment√© avec la librairie **kafka-python**

### üîπ Spark Consumer
- Lecture du topic Kafka en **Structured Streaming**
- Parsing des messages JSON
- Enrichissement des tickets avec une √©quipe de support :
  - `incident` ‚Üí Support Technique  
  - `demande` ‚Üí Customer Care  
  - `question` ‚Üí Support Information
- Affichage des tickets enrichis en console

### üîπ Spark Consumer Aggregation
- Traitement d‚Äôagr√©gation en temps r√©el
- Calcul du **nombre de tickets par type**
- Affichage des r√©sultats √† chaque micro-batch

### üîπ Redpanda Console
- Interface web pour visualiser les topics et les messages Kafka
- Accessible via : **http://localhost:8080**

---

## Lancement du projet

### Pr√©requis
- Docker
- Docker Compose
- Environnement Linux / **WSL recommand√©**

### Commande de d√©marrage
```bash
docker compose up --build

## Services d√©marr√©s

Les services suivants sont automatiquement lanc√©s via Docker Compose :

- Redpanda
- Redpanda Console
- Producer
- Spark Consumer
- Spark Consumer Aggregation

---

## Acc√®s aux interfaces

- **Redpanda Console** : http://localhost:8080

- **Spark UI** (si actif) :
  - Consumer : http://localhost:4040
  - Aggregation : http://localhost:4041

---

## R√©sultats observables

- Flux de tickets affich√©s en temps r√©el dans les logs Spark
- Agr√©gations mises √† jour √† chaque micro-batch
- Messages visibles dans Redpanda Console
- Pipeline stable et fonctionnel en continu

---

## Technologies utilis√©es

- Python 3
- Redpanda
- Apache Spark 3.4 (Structured Streaming)
- Kafka API
- Docker & Docker Compose
- Mermaid

---

## Limites et perspectives

### Limites
- Pas de persistance long terme (Data Lake ou base analytique)
- Pas de checkpoint Spark configur√© (POC volontairement simplifi√©)

### Perspectives
- Ajout d‚Äôun stockage **Parquet** ou **S3**
- Mise en place de checkpoints Spark
- Ajout d‚Äôun dashboard de visualisation (Grafana, Superset)
- D√©ploiement cloud (AWS MSK / EKS)

---

## D√©monstration vid√©o

Une courte vid√©o de d√©monstration accompagne ce projet et pr√©sente :
- Le lancement du pipeline
- L‚Äôingestion des tickets
- Les traitements Spark en temps r√©el

üìπ **[![D√©monstration du pipeline](https://cdn.loom.com/sessions/thumbnails/b77b8b460e284563b798f538fdab5176-with-play.gif)](https://www.loom.com/share/b77b8b460e284563b798f538fdab5176)**
