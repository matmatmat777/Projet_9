# üìä POC ‚Äì Gestion de tickets clients avec Redpanda et PySpark

## Contexte

Dans le cadre de l‚Äôexercice 2, InduTech souhaite r√©aliser un **POC (Proof Of Concept)** afin de d√©montrer la mise en place d‚Äôun **pipeline de donn√©es temps r√©el** pour la gestion de tickets clients.

Les tickets sont g√©n√©r√©s en continu, ing√©r√©s via **Redpanda (Kafka-compatible)**, puis consomm√©s et analys√©s **en temps r√©el avec PySpark Structured Streaming**.

Ce projet simule une architecture moderne orient√©e streaming, telle qu‚Äôelle pourrait √™tre d√©ploy√©e dans un environnement cloud (AWS).

---

## Objectifs du projet

- Configurer un cluster **Redpanda** pour l‚Äôingestion de donn√©es temps r√©el  
- Produire des tickets clients al√©atoires via un **script Python**  
- Consommer et transformer ces donn√©es avec **PySpark Structured Streaming**  
- G√©n√©rer des **insights temps r√©el** (enrichissements et agr√©gations)  
- Persister les r√©sultats dans une base relationnelle (**PostgreSQL**)  
- Orchestrer l‚Äôensemble avec **Docker Compose**

---

## Donn√©es manipul√©es

Chaque ticket client contient les champs suivants :

- `ticket_id` : identifiant unique du ticket  
- `client_id` : identifiant du client  
- `created_at` : date et heure de cr√©ation  
- `request` : description de la demande  
- `type` : type de demande (`incident`, `demande`, `question`)  
- `priority` : priorit√© (`low`, `medium`, `high`)  

---

## Architecture du pipeline

![Diagramme du pipeline streaming](media/Diagrammeexercice2.drawio1.png)

### Flux global

1. G√©n√©ration de tickets clients en continu (Producer Python)
2. Publication des tickets dans un topic Kafka (**Redpanda**)
3. Consommation temps r√©el par **PySpark Structured Streaming**
4. Deux traitements parall√®les :
   - Enrichissement m√©tier des tickets
   - Agr√©gation temps r√©el (nombre de tickets par type)
5. Persistance dans **PostgreSQL**
6. Visualisation et supervision via **Redpanda Console** et **Spark UI**

---

## Description des composants

### üîπ Redpanda
- Broker Kafka-compatible
- R√©ception des tickets en temps r√©el
- Topic principal : `client_tickets`
- Accessible sur le port **9092**
- Supervision via **Redpanda Console**

---

### üîπ Producer (Python)
- G√©n√®re des tickets clients al√©atoires en continu
- Envoie les messages JSON dans le topic `client_tickets`
- Impl√©ment√© en Python avec une librairie Kafka
- Simule une source applicative temps r√©el

---

### üîπ Spark Consumer (Enrichissement)
- Lecture du topic Kafka via **Structured Streaming**
- Parsing des messages JSON
- Enrichissement m√©tier :
  - `incident` ‚Üí **Support Technique**
  - `demande` ‚Üí **Customer Care**
  - `question` ‚Üí **Support Information**
- Affichage des tickets enrichis en console
- Persistance dans PostgreSQL (table `tickets`)

---

### üîπ Spark Consumer Aggregation
- Traitement d‚Äôagr√©gation temps r√©el
- Calcul du **nombre de tickets par type**
- Mise √† jour √† chaque micro-batch
- R√©sultats persist√©s dans PostgreSQL (table `tickets_aggregation`)

---

### üîπ PostgreSQL
- Stockage relationnel utilis√© pour le POC
- Centralise :
  - les tickets enrichis
  - les agr√©gations temps r√©el
- Utilis√© comme base op√©rationnelle (non analytique)

---

### üîπ Redpanda Console
- Interface web de supervision Kafka
- Visualisation :
  - topics
  - messages
  - partitions
- Accessible via : **http://localhost:8080**

> ‚ö†Ô∏è Les consumer groups Spark peuvent ne pas appara√Ætre comme des consumers Kafka classiques, car **Spark Structured Streaming g√®re les offsets via ses checkpoints internes**.

---

## Lancement du projet

### Pr√©requis
- Docker
- Docker Compose
- Environnement Linux / **WSL recommand√©**

### Commande de d√©marrage

```
docker compose up --build
```

## Services d√©marr√©s

- Redpanda
- Redpanda Console
- Producer de tickets
- Spark Consumer (enrichissement)
- Spark Consumer Aggregation
- PostgreSQL

---

## Acc√®s aux interfaces

### Redpanda Console
http://localhost:8080

### Spark UI

- Consumer : http://localhost:4040
- Aggregation : http://localhost:4041

### PostgreSQL

- Acc√®s via `psql` ou un client graphique (PgAdmin, DBeaver, etc.)

---

## R√©sultats observables

- Flux de tickets affich√©s en temps r√©el dans les logs Spark
- Tickets enrichis persist√©s en base PostgreSQL
- Agr√©gations mises √† jour √† chaque micro-batch
- Messages visibles dans Redpanda Console
- Pipeline stable et fonctionnel en continu

---

## Technologies utilis√©es

- Python 3
- Redpanda (Kafka-compatible)
- Apache Spark 3.4 ‚Äì Structured Streaming
- PostgreSQL
- Kafka API
- Docker & Docker Compose

---

## Limites et perspectives

### Limites

- PostgreSQL utilis√© uniquement √† des fins de d√©monstration
- Checkpoints Spark locaux (POC)
- Pas de supervision avanc√©e (metrics / alerting)

### Perspectives

- Stockage analytique (Parquet, Delta Lake, S3)
- Externalisation des checkpoints Spark
- Dashboards (Grafana, Superset)
- Scalabilit√© horizontale :
  - augmentation des partitions Kafka
  - ajout d‚Äôexecutors Spark
- D√©ploiement cloud (AWS MSK / EKS)

---

## D√©monstration vid√©o

Une courte vid√©o de d√©monstration accompagne ce projet :  
https://www.loom.com/share/3aedb1d4046a4cd084f1950a2c872f61

---

## Conclusion

Ce POC d√©montre la mise en place compl√®te d‚Äôun pipeline de streaming temps r√©el, depuis la g√©n√©ration des donn√©es jusqu‚Äô√† leur analyse et leur persistance, en s‚Äôappuyant sur des technologies modernes utilis√©es en production.
